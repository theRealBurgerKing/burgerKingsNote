Data Cleansing
数据清洗是用来处理脏数据，否则查询结果和分析结论都会出错。
现实数据存在多种统计偏差，需要在建模中平衡复杂性与准确性。

数据质量问题来自脏数据、转换错误、集成不一致和时间老化；这些问题可能以各种形式出现在数据集中，需要系统化清洗与管理。

数据质量问题既可能来自表结构设计（schema），也可能来自具体数据值（instance）。
Schema 层问题来自表结构或语义不一致；Instance 层问题来自具体数据记录的错误、重复或冲突，两者都是数据清洗必须处理的核心内容。

异常值会扭曲统计分析；
格式不一致（如日期格式）会导致集成时产生隐蔽而严重的数据错误。

👉 **主要信息：**  
**数据清洗并不总是正确，有时会把“真实但极端”的数据误认为是假数据。**

这是提醒我们：  
**数据清洗需要谨慎，不能盲目过滤异常值。**


# ✅ **核心要点（Conventional Definition of Data Quality）**

数据质量的传统五大指标：

### **1. Accuracy（准确性）**

数据是否正确记录。
Syntactic accuracy = 值是否是域中“可接受的格式”。
Semantic accuracy = 值是否与“真实世界的真值”一致。

### **2. Completeness（完整性）**

所有必要的信息是否都被记录。


### **(1) Schema completeness**

- 数据库模式是否有遗漏概念或属性  
    （例如：员工表里本该有“入职年份”却没有）
    

### **(2) Column completeness**

- 某一列是否有大量缺失值  
    （例如：地址字段 40% 缺失）
    

### **(3) Population completeness**

- 与“参考人口”相比是否缺人  
    （例如：应有 10,000 名客户，但数据库中只有 8,000 条记录）


### **1. 表的完整性 = 表在多大程度上正确代表真实世界**

完整性不只是“有没有缺失值”，而是：

- 表是否足够完整地反映现实中的对象
    
- NULL 值的含义在不同情境下不一样
    

### **2. NULL 的含义影响对完整性的判断**

例如：`email = NULL` 有三种可能：

1. **该人没有邮箱** → 不算不完整
    
2. **该人有邮箱但未记录** → 不完整
    
3. **不知道该人有没有邮箱** → 也可能不算不完整




不同系统对缺失数据的解释不同，会直接影响你对“完整性”的判断。
# ✅ **核心要点（OWA vs CWA — 完整性依赖世界假设）**

### **3. 完整性取决于是“开放世界”还是“封闭世界”假设**

---

## **Open World Assumption (OWA)**

- 未出现在数据中的事实 **不能判定为真或假**
    
- 数据库只是部分信息
    
- 未知 = 真的可能，也可能假的
    

例：  
问：“Paul 是法国公民吗？”  
数据没告诉你 → 答案是 **Unknown**

---

## **Closed World Assumption (CWA)**

- 数据库中不存在的信息视为 **不存在**（就是说数据库完美体现了世界）
    
- 有什么数据就是什么事实
    
- 未出现的事实都为 **假**
    

例：  
SQL 典型属于 CWA  
问：“Paul 是法国公民吗？”  
表中没有 → **No**
### **3. Uniqueness（唯一性）**

数据中是否避免重复记录。

### **4. Timeliness（及时性）**

数据是否最新、是否能反映当前状态。

### **5. Consistency（自洽性）**

数据是否违反语义规则


- 数据是否违反既定的 **语义规则** 或 **业务逻辑**
    
- 数据项之间是否能自洽、不冲突
    

### **典型例子：**

- **Integrity constraints（完整性约束）**
    
    - Domain constraints（值域约束）
        
    - Key constraints（主键约束）
        
    - Inclusion / Referential integrity（外键约束）
        
    - Functional dependencies（函数依赖）
        
- **Statistical edits（统计学中的语义规则）**  
    例如：年龄不能是负数，出生日期不能晚于注册日期。
    

👉 **主要信息：Consistency = 数据必须遵守语义/业务逻辑规则，否则就是不一致。**


# ==✅ **核心要点（Time-related Dimensions — 时间相关的数据质量维度）**==

==这一页讲 **三个与“时间”相关的数据质量指标**：==

---

# **1. Currency（新鲜度 / 更新及时性）**

### **核心概念：**

数据是 _多久以前更新的_？是否反映了当前真实状态？

### **示例：**

- 住址刚搬家后立即更新 → **currency 高**
    
- 住址多年未更新 → currency 低
    

👉 **主要信息：Currency 衡量数据更新是否及时。**

---

# **2. Volatility（波动性 / 数据变化频率）**

### **核心概念：**

数据 _随时间变化的频率_。

### **例子：**

- 出生日期 → 永不变化 → **volatility = 0**
    
- 股票报价 → 频繁变化 → **volatility 高**
    

👉 **主要信息：不同数据的“变化速度”不同，处理方式也应不同。**

---

# **3. Timeliness（时效性）**

### **核心概念：**

数据是否在**正确的时间**被提供，也就是“用得上”。

### **例子：**

- 大学课表在开课后才公布 → 信息虽然“最新”，但不及时 → **not timely**
    

👉 **主要信息：Timeliness = 数据是否在需要时可用，而不仅仅是最新。**

---

# 🎯 **一句话总结**

**时间相关的数据质量指标包括：Currency（更新是否及时）、Volatility（变化频率）、Timeliness（是否在需要时可用）。**









本页说明：**传统的数据质量定义本身就有局限性和问题**。

它提出三大问题：

---

# **1. Unmeasurable（难以衡量）**

- Accuracy、Completeness 等指标其实很难（甚至无法）严格量化
    
- 因为我们通常不知道“真实值”是什么
    
- 因此数据质量很难被客观测量
    

👉 **主要信息：数据质量的很多维度没有可操作的量化方法。**

---

# **2. Context dependent（依赖具体情境）**

- 不同任务对数据质量要求不同
    
- 某些场景允许更大的不准确  
    例如：做 aggregate（聚合统计）时个别错误值无所谓
    
- 没有统一标准判断哪些错误重要、哪些不重要
    

👉 **主要信息：数据质量不是绝对的，而是取决于使用场景。**

---

# **3. Vague（概念模糊）**

- 传统定义（如 Accuracy、Completeness、Timeliness…）  
    → 很抽象  
    → 没有告诉你 **如何实际改善数据质量**
    
- 定义本身无法指导实践
    

👉 **主要信息：数据质量的理论定义太模糊，缺乏可执行的改进指导。**

---

# 🎯 **一句话总结**

**传统的数据质量定义难以量化、依赖具体使用情境，而且过于抽象，无法直接指导实际数据清洗与改进工作。**







# 第二节：Exploring your Data in Pandas

在开始任何数据分析之前，你必须先“理解数据”。

Pandas Series 的关键概念：

一维数组结构
    
每个值都有一个对应的 label（index）
    
数据类型可以是整数、浮点、字符串等
    
类似 Python 列表，但带有标签
    

👉 主要信息：Series = 带标签的一维数据结构。

---

Pandas DataFrame 的关键概念：

二维表格（类似 Excel 表）
    
由多个 列（columns） 组成
    
每列可以是不同的数据类型（数字、字符串、布尔等）
    
有 row index 和 column index
    
是 Pandas 最核心的数据结构
    

👉 主要信息：DataFrame = 结构化二维表，支持混合类型列，是数据分析的主要容器。

**Pandas 的核心数据结构是 Series（一维带索引）和 DataFrame（二维表格）。**



Pandas 提供 describe()、shape、head()/tail()、sample()、dtypes 等方法，帮助分析者快速理解数据结构、类型与质量，是数据分析的第一步。用 `list(df)` 查看 DataFrame 的列名是理解数据结构的重要方法