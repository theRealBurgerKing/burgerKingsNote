Introduction to Deep Learning

## 为什么使用深度学习

- **擅长处理非结构化数据**：深度学习在处理图像、文本、音频等非结构化数据方面表现出色
- **数据越多，学习效果越好**：深度学习模型能够随着数据量的增加而不断提升性能
- **在某些情况下更准确**：相比传统方法，深度学习在特定任务上可以达到更高的准确率
- **不需要大量特征工程**：深度学习可以自动学习特征，减少了手动设计特征的工作量

## 何时使用深度学习

- **数据量充足时**：当数据集规模较大时，深度学习优于其他技术。但如果数据量较小，传统机器学习算法可能更合适
- **需要高端基础设施**：深度学习技术需要强大的计算资源（如GPU）才能在合理时间内完成训练
- **缺乏领域知识进行特征选择时**：当你不确定如何进行特征工程时，深度学习可以自动发现特征，表现往往优于其他方法
- **处理复杂问题时**：深度学习在图像分类、自然语言处理和语音识别等复杂问题上表现尤为突出



### 命名规范：N层神经网络

一般规则：

- **N - 1 层隐藏单元**
- **一层输出层**
- 输入层不计入层数




## 前向传播的工作流程

### 数据流动过程：

1. **输入层**：输入神经元首先接收对象的数据特征。处理数据后，将输出发送到第一个隐藏层。
2. **隐藏层处理**：隐藏层处理这些输出，并将结果发送到下一个隐藏层。
3. **层层传递**：这个过程持续进行，直到数据到达最终的输出层。
4. **输出层**：输出值决定了对象的分类结果。

整个过程被称为**前向传播（Forward Propagation）**或**前向传递（Forward prop）**。






### 训练神经网络的步骤（循环直到收敛）：

**对于每个训练样本 n：**

1. **前向传播（Forward Pass）**
    - 给定输入 x⁽ⁿ⁾
    - 将活动向前传播：x⁽ⁿ⁾ → h⁽ⁿ⁾ → o⁽ⁿ⁾
    - 计算网络的输出
2. **反向传播（Backward Pass）**
    - 将梯度向后传播
    - ==计算每层参数相对于损失函数的梯度==
3. **权重更新**
    - ==使用梯度下降法更新每个权重==
    - ==调整权重以最小化误差==

这个过程不断重复（迭代），直到网络收敛（即模型性能不再显著提升）。反向传播算法的核心优势在于它能够高效地计算深层网络中所有参数的梯度，使得训练大规模神经网络成为可能。






## 反向传播的数学原理

### 目标：寻找最优权重

__w_ = argmin_w Σ(n=1 to N) loss(o⁽ⁿ⁾, t⁽ⁿ⁾)_*

其中 **o = f(x; w)** 是神经网络的输出

### 损失函数的定义

两种常用的损失函数：

1. **平方损失（Squared Loss）**：
    - ½(o_k⁽ⁿ⁾ - t_k⁽ⁿ⁾)²
    - 用于回归问题
2. **交叉熵损失（Cross-entropy Loss）**：
    - -t_k⁽ⁿ⁾ log o_k⁽ⁿ⁾
    - 用于分类问题

### 梯度下降更新规则

**w^(t+1) = w^t - η ∂E/∂w^t**

其中：

- **η** 是学习率（控制每次更新的步长）
- **E** 是误差/损失
- **∂E/∂w^t** 是损失对权重的梯度

反向传播算法高效地计算这个梯度，使得我们能够更新网络中的所有权重。

## 深度神经网络的主要类型

### 1. **前馈网络（Feedforward Networks, FFN）**

- ==**最适用场景**：当我们对输出有明确预期时==
- 信息单向流动，从输入到输出
- 适合标准的分类和回归任务

### 2. **循环神经网络（Recurrent Neural Network, RNN）**

- ==**最适用场景**：时间序列数据==
- 具有记忆能力，可以处理序列信息
- 适合语音识别、语言建模、机器翻译等

### 3. **卷积神经网络（Convolutional Neural Network, CNN）**

- ==**最适用场景**：图像、文本、语音识别==
- 通过卷积层提取空间特征
- 在计算机视觉任务中表现卓越

每种网络架构都针对特定类型的数据和问题进行了优化，选择合适的网络类型对于获得良好的性能至关重要。







## 深度神经网络的弱点

### 1. **需要大量数据集**

深度学习需要大量数据，因此训练周期很长。

### 2. **部署成本高**

就成本而言，像SVM和其他树集成等机器学习方法非常容易部署，即使是相对缺乏机器学习经验的新手也能使用，并且通常能获得相当好的结果。

### 3. **倾向于学习所有特征**

深度学习方法往往会学习所有东西。最好能够将图像（或音频或文本）结构的先验知识编码到模型中。

### 4. **学到的特征难以理解**

学到的特征通常难以理解。许多视觉特征也不是真正人类可理解的（例如，不同特征的串联/组合）。

### 5. **需要深入理解建模方法**

需要充分理解如何使用传统工具对多模态数据进行建模。

这些弱点说明了深度学习并非万能，在某些情况下，传统机器学习方法可能更合适、更经济、更易于实现。