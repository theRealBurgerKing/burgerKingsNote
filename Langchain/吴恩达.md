Parser：接受输出，将输出解释成更格式化的形式

temperater，模型的随机性

langchain有一个ChatPromptTemple的库用于反复使用某个模板，而不是使用f字符串
有用的抽象，提高复用性
此外，它还支持输出解析
ReAct框架
ReAct = **Re**asoning + **Act**ing，让 LLM 像人一样"边思考边行动"地解决问题，循环执行三个步骤：

```
Thought  →  Action  →  Observation  →  Thought  →  ...
```




用 `StructuredOutputParser` 将模型返回的字符串自动解析为 Python 字典
上一步模型返回的 `response.content` 只是一个**普通字符串**，虽然内容长得像 JSON，但本质是 `str`，所以调用 `.get()` 会报 `AttributeError`。这就是为什么需要引入输出解析器。

第一步：定义每个字段的 Schema
用 `ResponseSchema` 定义每个字段的名称和描述，相当于告诉解析器"我期望输出哪些字段、每个字段是什么含义"。

第二步：创建解析器并生成格式指令
`get_format_instructions()` 会自动生成一段提示文字（如图2所示），内容大致是：

> 请用 markdown 的 json 代码块格式输出，结构如下：
> 
> json
> 
> ```json
> {
>   "gift": string,
>   "delivery_days": string,
>   "price_value": string
> }
> ```

这段指令会被**插入到发给模型的 Prompt 中**，引导模型按照固定格式输出，方便后续解析。