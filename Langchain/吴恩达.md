## 模型，提示和输出解析
Parser：接受输出，将输出解释成更格式化的形式

temperater，模型的随机性

langchain有一个ChatPromptTemple的库用于反复使用某个模板，而不是使用f字符串
有用的抽象，提高复用性
此外，它还支持输出解析
ReAct框架
ReAct = **Re**asoning + **Act**ing，让 LLM 像人一样"边思考边行动"地解决问题，循环执行三个步骤：

```
Thought  →  Action  →  Observation  →  Thought  →  ...
```




用 `StructuredOutputParser` 将模型返回的字符串自动解析为 Python 字典
上一步模型返回的 `response.content` 只是一个**普通字符串**，虽然内容长得像 JSON，但本质是 `str`，所以调用 `.get()` 会报 `AttributeError`。而我们想要一个dict，这就是为什么需要引入输出解析器。

第一步：定义每个字段的 Schema
用 `ResponseSchema` 定义每个字段的名称和描述，相当于告诉解析器"我期望输出哪些字段、每个字段是什么含义"。

第二步：创建解析器并生成格式指令
`get_format_instructions()` 会自动生成一段提示文字（如图2所示），内容大致是：

> 请用 markdown 的 json 代码块格式输出，结构如下：
> 
> json
> 
> ```json
> {
>   "gift": string,
>   "delivery_days": string,
>   "price_value": string
> }
> ```

这段指令会被**插入到发给模型的 Prompt 中**，引导模型按照固定格式输出，方便后续解析。



## Memory
`verbose=True` 是一个**调试开关**，控制是否在控制台打印 LangChain 内部的详细运行过程。
memory.buffer查看 
memory.save_context自己写记录

大语言模型是"无状态的"

每次对话都是独立的

LLM 本身没有记忆能力，每次你发送一条消息，对模型来说都是一个全新的、独立的请求。它不会自动记住你上一句说了什么。

那聊天机器人为什么"看起来"有记忆？

这是一个障眼法——每次发送新消息时，程序会把**之前所有的对话历史**一起打包发给模型





## LangChain 的几种 Memory 策略对比

---

### 1. `ConversationBufferMemory`（缓冲记忆）

**保留全部对话历史**

python

```python
memory = ConversationBufferMemory()
```

- 优点：完整保留所有上下文，回答最准确
- 缺点：对话越长 Token 消耗越多，长对话费用爆炸
- 适合：短对话场景

---

### 2. `ConversationBufferWindowMemory`（窗口记忆）

**只保留最近 K 轮对话**

python

```python
memory = ConversationBufferWindowMemory(k=2)  # 只记住最近2轮
```

- 优点：Token 消耗固定可控，不会随对话增长
- 缺点：超出窗口的内容直接丢弃，模型会"忘事"
- 适合：对早期历史不敏感的场景

变体：
### `ConversationTokenBufferMemory`（Token 缓冲记忆）
按 Token 数量而非轮数来决定保留多少历史

---

### 3. `ConversationSummaryMemory`（摘要记忆）

**把历史对话压缩成摘要**

python

```python
memory = ConversationSummaryMemory(llm=llm)
```

- 优点：对话再长也不会无限增长，保留了大致语义
- 缺点：摘要会丢失细节，而且压缩本身也要消耗 Token
- 适合：长对话但不需要精确回忆细节的场景

---

### 4. `ConversationSummaryBufferMemory`（摘要+缓冲混合）

**近期对话原文保留，早期对话压缩成摘要**

python

```python
memory = ConversationSummaryBufferMemory(llm=llm, max_token_limit=100)
```

- 优点：兼顾近期精度和长期语义，是上面两种的折中
- 缺点：实现最复杂，需要设置 token 阈值
- 适合：既有长对话又需要记住近期细节的场景